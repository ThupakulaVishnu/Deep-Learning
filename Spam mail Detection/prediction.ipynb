{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model=load_model('spam_mail_model.h5')\n",
    "\n",
    "with open('stopwords.pkl','rb') as file:\n",
    "    all_stopwords=pickle.load(file)\n",
    "\n",
    "with open('preprocessing.pkl','rb') as file:\n",
    "    preprocessing=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub(r'[^a-z\\s!?]','',text)\n",
    "    text=re.sub(r'\\s+',' ',text)\n",
    "    sentance=[]\n",
    "    for word in text.split():\n",
    "        if word not in all_stopwords:\n",
    "            sentance.append(word)\n",
    "    return ' '.join(w for w in sentance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    text=preprocessing['nlp'](text)\n",
    "    return ' '.join(word.lemma_ for word in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def prediction(text):\n",
    "    preproc=convert(text)\n",
    "    lemmatization=lemmatize_text(preproc)\n",
    "    sequence=preprocessing['tokenizer'].texts_to_sequences([lemmatization])\n",
    "    padding=pad_sequences(sequence,maxlen=preprocessing['max_length'], padding='post', truncating='post')\n",
    "    predict=model.predict(padding)[0][0]\n",
    "    return 1 if predict>0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"Subject: Invitation for Interview â€“ Software Engineer Position\n",
    "Body:\n",
    "Dear Applicant,\n",
    "\n",
    "Thank you for applying for the Software Engineer position at our company. We are pleased to invite you for an interview.\n",
    "\n",
    "ğŸ“… Date: March 12, 2025\n",
    "â° Time: 10:00 AM\n",
    "ğŸ“ Location: ABC Corp, 123 Street, NY\n",
    "\n",
    "Please reply to confirm your availability. Looking forward to meeting you!\n",
    "\n",
    "Best Regards,\n",
    "HR Team\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
      "Ham\n"
     ]
    }
   ],
   "source": [
    "if prediction(text):\n",
    "    print(\"spam\")\n",
    "else:\n",
    "    print(\"Ham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
