{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\vishn\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load trained model\n",
    "model = load_model('spam_mail_model.h5')\n",
    "\n",
    "# Load stopwords\n",
    "with open('stopwords.pkl','rb') as file:\n",
    "    all_stopwords = pickle.load(file)\n",
    "\n",
    "# Load preprocessing objects\n",
    "with open('preprocessing.pkl','rb') as file:\n",
    "    preprocessing = pickle.load(file)\n",
    "\n",
    "word2vec_model = preprocessing['word2vec_model']\n",
    "max_len = preprocessing['max_length']\n",
    "label_encoder = preprocessing['label_encoder']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s!?]','',text)\n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    words = [w for w in text.split() if w not in all_stopwords]\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    # Use the same NLP object from training\n",
    "    nlp = preprocessing.get('nlp', None)\n",
    "    if nlp is None:\n",
    "        raise ValueError(\"NLP object not found in preprocessing\")\n",
    "    doc = nlp(text)\n",
    "    return ' '.join(word.lemma_ for word in doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vectors(text):\n",
    "    words = text.split()\n",
    "    vecs = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "    # Pad or truncate\n",
    "    if len(vecs) < max_len:\n",
    "        vecs.extend([[0]*word2vec_model.vector_size]*(max_len - len(vecs)))\n",
    "    else:\n",
    "        vecs = vecs[:max_len]\n",
    "    return np.array([vecs])\n",
    "\n",
    "def predict_spam(text):\n",
    "    cleaned = clean_text(text)\n",
    "    lemmatized = lemmatize_text(cleaned)\n",
    "    padded_vecs = text_to_vectors(lemmatized)\n",
    "    pred = model.predict(padded_vecs)[0][0]\n",
    "    return 1 if pred > 0.5 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Subject: Invitation for Interview ‚Äì Software Engineer Position\n",
    "Body:\n",
    "Dear Applicant,\n",
    "\n",
    "Thank you for applying for the Software Engineer position at our company. We are pleased to invite you for an interview.\n",
    "\n",
    "üìÖ Date: March 12, 2025\n",
    "‚è∞ Time: 10:00 AM\n",
    "üìç Location: ABC Corp, 123 Street, NY\n",
    "\n",
    "Please reply to confirm your availability. Looking forward to meeting you!\n",
    "\n",
    "Best Regards,\n",
    "HR Team\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641ms/step\n",
      "Ham\n"
     ]
    }
   ],
   "source": [
    "if predict_spam(text):\n",
    "    print(\"Spam\")\n",
    "else:\n",
    "    print(\"Ham\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
